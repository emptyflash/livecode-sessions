<html>
    <head>
        <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/emptyflash/GlslCanvas@master/dist/GlslCanvas.js"></script>
        <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/joewalnes/reconnecting-websocket@master/reconnecting-websocket.min.js"></script>
    </head>

    <style>
            body {
                background: #101515;
                overflow-y: hidden;
                padding: 0px;
                margin: 0px;
            }

            #canvas {
                width: 100%;
                height: 100%;
            }
    </style>

    <body>
        <canvas data-textures="puppy.jpg" id="canvas"/>
    </body>

    <script type="text/javascript">
        const canvas = document.getElementById("canvas");
        const sandbox = new GlslCanvas(canvas);
        fetch('std.frag')
            .then(r => r.text())
            .then(std => {
                fetch("shader.frag").then(r => r.text()).then(shader => {
                    sandbox.load(std + shader);
                });
                const scheme = window.location.protocol.includes("s") ? "wss" : "ws";
                var ws = new ReconnectingWebSocket(`${scheme}://${window.location.host}/websocket`);
                ws.onopen = function() {
                    console.log('CONNECT');
                };
                ws.onclose = function(data) {
                    console.log('DISCONNECT', data);
                };
                let currentShader = "";
                ws.onmessage = function(event) {
                    if (event.data === '---') {
                        console.log(currentShader);
                        if (currentShader.trim() === "") {
                            return;
                        }
                        sandbox.load(std + currentShader);
                        currentShader = "";
                    } else {
                        currentShader += event.data + '\n';
                    }
                };
            });

        const audioCtx = new AudioContext();

        if (audioCtx.state === 'suspended') {
            const unlock = () => {
                audioCtx.resume().then(() => {
                        document.body.removeEventListener('touchstart', unlock);
                        document.body.removeEventListener('touchend', unlock);
                        document.body.removeEventListener('click', unlock);
                    });
            };

            document.body.addEventListener('touchstart', unlock, false);
            document.body.addEventListener('touchend', unlock, false);
            document.body.addEventListener('click', unlock, false);
        }
        const analyser = audioCtx.createAnalyser();
        //analyser.minDecibels = -90;
        //analyser.maxDecibels = -10;
        analyser.fftSize = 32;
        //analyser.smoothingTimeConstant = 0.85;

        let success = true;
        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
            const source = audioCtx.createMediaStreamSource(stream);
            source.connect(analyser);
        }).catch(() => { success = false; });

        const samples = analyser.frequencyBinCount;
        const spectrumBuffer = new Uint8Array(samples);
        let firstRender = true;
        sandbox.on('render', () => {
            if (firstRender) {
                sandbox.width = sandbox.width - 1;
                firstRender = false;
            }
            analyser.getByteFrequencyData(spectrumBuffer);
            let audio = [spectrumBuffer[2], spectrumBuffer[6], spectrumBuffer[10], spectrumBuffer[14]];
            if (!success) {
                const time = new Date();
                audio = [Math.sin(time), Math.sin(+time + 1), Math.sin(+time + 2), Math.sin(+time + 3)].map(a => a * 255);

                console.log(audio)
            }
            sandbox.setUniforms({'u_audio': audio});

            const gl = sandbox.gl;
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, gl.canvas);
        });
    </script>
</html>

